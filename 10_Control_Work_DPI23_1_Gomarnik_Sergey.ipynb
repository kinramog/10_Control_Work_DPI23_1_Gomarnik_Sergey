{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgY04w_zsL3Q"
      },
      "source": [
        "# Введение в обработку текста на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OglZ79AcsL3S"
      },
      "source": [
        "Материалы:\n",
        "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
        "* https://realpython.com/nltk-nlp-python/\n",
        "* https://scikit-learn.org/stable/modules/feature_extraction.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw9-pI05sL3S"
      },
      "source": [
        "## Задачи для совместного разбора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vo7QBlqsL3T",
        "outputId": "dd9c3e97-1b62-4a9d-d60e-ad65cb7ce236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hblPFD1JsL3U"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEpaT_EzsL3U"
      },
      "source": [
        "1. Считайте слова из файла `litw-win.txt` и запишите их в список `words`. В заданном предложении исправьте все опечатки, заменив слова с опечатками на ближайшие (в смысле расстояния Левенштейна) к ним слова из списка `words`. Считайте, что в слове есть опечатка, если данное слово не содержится в списке `words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L0yAw5_sL3U",
        "outputId": "e6b13342-548e-436a-80b8-becf950d873d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3o140g3sL3U",
        "outputId": "065b37a6-df6c-4396-89ae-6d2a91247c6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['и',\n",
              " 'в',\n",
              " 'я',\n",
              " 'с',\n",
              " 'а',\n",
              " 'к',\n",
              " 'у',\n",
              " 'о',\n",
              " 'н',\n",
              " 'п',\n",
              " 'ж',\n",
              " 'б',\n",
              " 'т',\n",
              " 'д',\n",
              " 'м',\n",
              " 'ч',\n",
              " 'з',\n",
              " 'г',\n",
              " 'е',\n",
              " 'р',\n",
              " 'э',\n",
              " 'л',\n",
              " 'х',\n",
              " 'ш',\n",
              " 'ф',\n",
              " 'ц',\n",
              " 'щ',\n",
              " 'й',\n",
              " 'ю',\n",
              " 'ы',\n",
              " 'ъ',\n",
              " 'ь',\n",
              " 'не',\n",
              " 'на',\n",
              " 'он',\n",
              " 'то',\n",
              " 'но',\n",
              " 'же',\n",
              " 'вы',\n",
              " 'по',\n",
              " 'да',\n",
              " 'за',\n",
              " 'бы',\n",
              " 'ты',\n",
              " 'от',\n",
              " 'из',\n",
              " 'ее',\n",
              " 'до',\n",
              " 'ну',\n",
              " 'ни',\n",
              " 'ли',\n",
              " 'уж',\n",
              " 'во',\n",
              " 'их',\n",
              " 'мы',\n",
              " 'со',\n",
              " 'ей',\n",
              " 'об',\n",
              " 'ко',\n",
              " 'ах',\n",
              " 'им',\n",
              " 'ка',\n",
              " 'та',\n",
              " 'пр',\n",
              " 'те',\n",
              " 'чт',\n",
              " 'ту',\n",
              " 'го',\n",
              " 'де',\n",
              " 'вс',\n",
              " 'эт',\n",
              " 'мо',\n",
              " 'ра',\n",
              " 'ст',\n",
              " 'ха',\n",
              " 'хе',\n",
              " 'ум',\n",
              " 'се',\n",
              " 'эх',\n",
              " 'гм',\n",
              " 'ме',\n",
              " 'св',\n",
              " 'ль',\n",
              " 'ег',\n",
              " 'пе',\n",
              " 'ва',\n",
              " 'са',\n",
              " 'ве',\n",
              " 'ох',\n",
              " 'бо',\n",
              " 'хо',\n",
              " 'че',\n",
              " 'сл',\n",
              " 'од',\n",
              " 'бе',\n",
              " 'мн',\n",
              " 'ай',\n",
              " 'ею',\n",
              " 'ос',\n",
              " 'ск',\n",
              " 'ви',\n",
              " 'ми',\n",
              " 'ма',\n",
              " 'сп',\n",
              " 'ба',\n",
              " 'ес',\n",
              " 'бу',\n",
              " 'гл',\n",
              " 'що',\n",
              " 'эй',\n",
              " 'ем',\n",
              " 'кр',\n",
              " 'см',\n",
              " 'др',\n",
              " 'лю',\n",
              " 'па',\n",
              " 'ро',\n",
              " 'зн',\n",
              " 'ле',\n",
              " 'як',\n",
              " 'тр',\n",
              " 'жи',\n",
              " 'ел',\n",
              " 'ус',\n",
              " 'фу',\n",
              " 'дв',\n",
              " 'ру',\n",
              " 'ал',\n",
              " 'ой',\n",
              " 'си',\n",
              " 'ду',\n",
              " 'вз',\n",
              " 'ещ',\n",
              " 'хи',\n",
              " 'чи',\n",
              " 'вд',\n",
              " 'ил',\n",
              " 'ух',\n",
              " 'ча',\n",
              " 'гр',\n",
              " 'пи',\n",
              " 'бл',\n",
              " 'ре',\n",
              " 'су',\n",
              " 'ге',\n",
              " 'ку',\n",
              " 'оп',\n",
              " 'жа',\n",
              " 'ис',\n",
              " 'оч',\n",
              " 'эк',\n",
              " 'дл',\n",
              " 'пл',\n",
              " 'ин',\n",
              " 'пу',\n",
              " 'фр',\n",
              " 'ан',\n",
              " 'бр',\n",
              " 'чу',\n",
              " 'му',\n",
              " 'ув',\n",
              " 'вп',\n",
              " 'кн',\n",
              " 'ив',\n",
              " 'ок',\n",
              " 'ад',\n",
              " 'лу',\n",
              " 'уг',\n",
              " 'вр',\n",
              " 'ло',\n",
              " 'це',\n",
              " 'гу',\n",
              " 'ла',\n",
              " 'ше',\n",
              " 'ср',\n",
              " 'ти',\n",
              " 'уд',\n",
              " 'фе',\n",
              " 'ди',\n",
              " 'тв',\n",
              " 'гд',\n",
              " 'сд',\n",
              " 'вн',\n",
              " 'ид',\n",
              " 'уб',\n",
              " 'щи',\n",
              " 'зд',\n",
              " 'уп',\n",
              " 'сч',\n",
              " 'уз',\n",
              " 'га',\n",
              " 'ог',\n",
              " 'ул',\n",
              " 'ша',\n",
              " 'ар',\n",
              " 'ут',\n",
              " 'фи',\n",
              " 'аж',\n",
              " 'ед',\n",
              " 'кт',\n",
              " 'гг',\n",
              " 'кл',\n",
              " 'сн',\n",
              " 'ук',\n",
              " 'зе',\n",
              " 'иг',\n",
              " 'зи',\n",
              " 'ки',\n",
              " 'ца',\n",
              " 'яр',\n",
              " 'дн',\n",
              " 'мя',\n",
              " 'сы',\n",
              " 'фа',\n",
              " 'вм',\n",
              " 'зл',\n",
              " 'ож',\n",
              " 'сю',\n",
              " 'шу',\n",
              " 'пя',\n",
              " 'тя',\n",
              " 'шл',\n",
              " 'шт',\n",
              " 'вл',\n",
              " 'ля',\n",
              " 'ор',\n",
              " 'хр',\n",
              " 'ще',\n",
              " 'ак',\n",
              " 'дя',\n",
              " 'ит',\n",
              " 'уч',\n",
              " 'ху',\n",
              " 'ши',\n",
              " 'фо',\n",
              " 'яв',\n",
              " 'би',\n",
              " 'ды',\n",
              " 'ры',\n",
              " 'уй',\n",
              " 'юг',\n",
              " 'вв',\n",
              " 'иб',\n",
              " 'кв',\n",
              " 'сб',\n",
              " 'сх',\n",
              " 'сь',\n",
              " 'зв',\n",
              " 'ол',\n",
              " 'тс',\n",
              " 'яд',\n",
              " 'аз',\n",
              " 'вч',\n",
              " 'ет',\n",
              " 'зу',\n",
              " 'ке',\n",
              " 'хл',\n",
              " 'аг',\n",
              " 'ев',\n",
              " 'еж',\n",
              " 'жд',\n",
              " 'ны',\n",
              " 'ов',\n",
              " 'пь',\n",
              " 'яс',\n",
              " 'вт',\n",
              " 'зо',\n",
              " 'ня',\n",
              " 'оз',\n",
              " 'оф',\n",
              " 'ош',\n",
              " 'ся',\n",
              " 'тю',\n",
              " 'уе',\n",
              " 'ун',\n",
              " 'уш',\n",
              " 'хм',\n",
              " 'ав',\n",
              " 'жу',\n",
              " 'мл',\n",
              " 'мм',\n",
              " 'ри',\n",
              " 'ть',\n",
              " 'чр',\n",
              " 'шк',\n",
              " 'ап',\n",
              " 'ас',\n",
              " 'нр',\n",
              " 'сг',\n",
              " 'сс',\n",
              " 'чш',\n",
              " 'юн',\n",
              " 'яй',\n",
              " 'ам',\n",
              " 'вг',\n",
              " 'ву',\n",
              " 'вх',\n",
              " 'дю',\n",
              " 'км',\n",
              " 'мг',\n",
              " 'ом',\n",
              " 'ощ',\n",
              " 'пы',\n",
              " 'рт',\n",
              " 'рю',\n",
              " 'ря',\n",
              " 'сф',\n",
              " 'сц',\n",
              " 'ур',\n",
              " 'хв',\n",
              " 'шп',\n",
              " 'шю',\n",
              " 'ая',\n",
              " 'бя',\n",
              " 'ги',\n",
              " 'гн',\n",
              " 'дж',\n",
              " 'ер',\n",
              " 'ик',\n",
              " 'ищ',\n",
              " 'съ',\n",
              " 'фл',\n",
              " 'чь',\n",
              " 'шо',\n",
              " 'яз',\n",
              " 'аи',\n",
              " 'ат',\n",
              " 'ау',\n",
              " 'вк',\n",
              " 'вя',\n",
              " 'ие',\n",
              " 'ий',\n",
              " 'кс',\n",
              " 'кх',\n",
              " 'тц',\n",
              " 'уа',\n",
              " 'цв',\n",
              " 'ци',\n",
              " 'эп',\n",
              " 'юх',\n",
              " 'ен',\n",
              " 'еф',\n",
              " 'ех',\n",
              " 'зы',\n",
              " 'иа',\n",
              " 'иж',\n",
              " 'ии',\n",
              " 'ио',\n",
              " 'ип',\n",
              " 'ич',\n",
              " 'лы',\n",
              " 'мс',\n",
              " 'мф',\n",
              " 'нс',\n",
              " 'ое',\n",
              " 'оц',\n",
              " 'пш',\n",
              " 'сж',\n",
              " 'сш',\n",
              " 'тщ',\n",
              " 'уф',\n",
              " 'цо',\n",
              " 'цу',\n",
              " 'чо',\n",
              " 'шш',\n",
              " 'эс',\n",
              " 'юм',\n",
              " 'ют',\n",
              " 'аб',\n",
              " 'аф',\n",
              " 'аш',\n",
              " 'бь',\n",
              " 'бю',\n",
              " 'вш',\n",
              " 'въ',\n",
              " 'гв',\n",
              " 'гю',\n",
              " 'дз',\n",
              " 'дм',\n",
              " 'дь',\n",
              " 'еш',\n",
              " 'жр',\n",
              " 'зг',\n",
              " 'зз',\n",
              " 'зр',\n",
              " 'иу',\n",
              " 'иф',\n",
              " 'кь',\n",
              " 'лб',\n",
              " 'лг',\n",
              " 'лж',\n",
              " 'лт',\n",
              " 'мр',\n",
              " 'мч',\n",
              " 'нь',\n",
              " 'нэ',\n",
              " 'ню',\n",
              " 'пт',\n",
              " 'сз',\n",
              " 'тк',\n",
              " 'тл',\n",
              " 'тт',\n",
              " 'тэ',\n",
              " 'уи',\n",
              " 'ущ',\n",
              " 'ую',\n",
              " 'фэ',\n",
              " 'цы',\n",
              " 'шв',\n",
              " 'шм',\n",
              " 'шь',\n",
              " 'ща',\n",
              " 'щу',\n",
              " 'ые',\n",
              " 'ый',\n",
              " 'ыч',\n",
              " 'эа',\n",
              " 'эл',\n",
              " 'эм',\n",
              " 'эн',\n",
              " 'эф',\n",
              " 'ээ',\n",
              " 'юб',\n",
              " 'юл',\n",
              " 'юс',\n",
              " 'яб',\n",
              " 'ян',\n",
              " 'ят',\n",
              " 'ях',\n",
              " 'ящ',\n",
              " 'что',\n",
              " 'как',\n",
              " 'это',\n",
              " 'все',\n",
              " 'его',\n",
              " 'так',\n",
              " 'она',\n",
              " 'мне',\n",
              " 'еще',\n",
              " 'вот',\n",
              " 'был',\n",
              " 'ему',\n",
              " 'нет',\n",
              " 'уже',\n",
              " 'вас',\n",
              " 'вам',\n",
              " 'или',\n",
              " 'для',\n",
              " 'они',\n",
              " 'тут',\n",
              " 'сам',\n",
              " 'чем',\n",
              " 'раз',\n",
              " 'там',\n",
              " 'где',\n",
              " 'под',\n",
              " 'без',\n",
              " 'ней',\n",
              " 'кто',\n",
              " 'мой',\n",
              " 'ним',\n",
              " 'тем',\n",
              " 'при',\n",
              " 'про',\n",
              " 'нас',\n",
              " 'них',\n",
              " 'мог',\n",
              " 'нее',\n",
              " 'эти',\n",
              " 'тот',\n",
              " 'два',\n",
              " 'том',\n",
              " 'всю',\n",
              " 'над',\n",
              " 'три',\n",
              " 'эту',\n",
              " 'лет',\n",
              " 'нем',\n",
              " 'нам',\n",
              " 'бог',\n",
              " 'вся',\n",
              " 'эта',\n",
              " 'моя',\n",
              " 'мое',\n",
              " 'оно',\n",
              " 'всг',\n",
              " 'пор',\n",
              " 'две',\n",
              " 'наш',\n",
              " 'мои',\n",
              " 'дня',\n",
              " 'тех',\n",
              " 'час',\n",
              " 'дом',\n",
              " 'ибо',\n",
              " 'мою',\n",
              " 'сих',\n",
              " 'нею',\n",
              " 'оба',\n",
              " 'вон',\n",
              " 'той',\n",
              " 'вид',\n",
              " 'год',\n",
              " 'ваш',\n",
              " 'дал',\n",
              " 'сел',\n",
              " 'кое',\n",
              " 'ума',\n",
              " 'сто',\n",
              " 'рад',\n",
              " 'дай',\n",
              " 'обо',\n",
              " 'чай',\n",
              " 'пол',\n",
              " 'рук',\n",
              " 'шел',\n",
              " 'нос',\n",
              " 'дам',\n",
              " 'обе',\n",
              " 'дни',\n",
              " 'сей',\n",
              " 'сон',\n",
              " 'кем',\n",
              " 'муж',\n",
              " 'сын',\n",
              " 'имя',\n",
              " 'жил',\n",
              " 'рот',\n",
              " 'дух',\n",
              " 'сил',\n",
              " 'мир',\n",
              " 'ног',\n",
              " 'уме',\n",
              " 'пан',\n",
              " 'сне',\n",
              " 'ста',\n",
              " 'шею',\n",
              " 'сад',\n",
              " 'чаю',\n",
              " 'изо',\n",
              " 'сво',\n",
              " 'миг',\n",
              " 'век',\n",
              " 'мол',\n",
              " 'пот',\n",
              " 'шум',\n",
              " 'дел',\n",
              " 'дед',\n",
              " 'иди',\n",
              " 'пер',\n",
              " 'лиц',\n",
              " 'сем',\n",
              " 'лес',\n",
              " 'тек',\n",
              " 'шла',\n",
              " 'шаг',\n",
              " 'очи',\n",
              " 'душ',\n",
              " 'суд',\n",
              " 'гор',\n",
              " 'пре',\n",
              " 'тон',\n",
              " 'иду',\n",
              " 'тол',\n",
              " 'лег',\n",
              " 'шли',\n",
              " 'пил',\n",
              " 'зна',\n",
              " 'али',\n",
              " 'ими',\n",
              " 'ком',\n",
              " 'мен',\n",
              " 'рас',\n",
              " 'ухо',\n",
              " 'сию',\n",
              " 'кой',\n",
              " 'уши',\n",
              " 'иль',\n",
              " 'одн',\n",
              " 'бол',\n",
              " 'пос',\n",
              " 'вне',\n",
              " 'буд',\n",
              " 'кот',\n",
              " 'лбу',\n",
              " 'кум',\n",
              " 'аль',\n",
              " 'жду',\n",
              " 'лоб',\n",
              " 'ска',\n",
              " 'сна',\n",
              " 'стр',\n",
              " 'вор',\n",
              " 'шее',\n",
              " 'жив',\n",
              " 'меж',\n",
              " 'гов',\n",
              " 'сие',\n",
              " 'ест',\n",
              " 'лев',\n",
              " 'воз',\n",
              " 'фон',\n",
              " 'мож',\n",
              " 'дру',\n",
              " 'кхи',\n",
              " 'еду',\n",
              " 'себ',\n",
              " 'вел',\n",
              " 'увы',\n",
              " 'жид',\n",
              " 'род',\n",
              " 'теб',\n",
              " 'усы',\n",
              " 'шло',\n",
              " 'пок',\n",
              " 'губ',\n",
              " 'ишь',\n",
              " 'бал',\n",
              " 'ког',\n",
              " 'даж',\n",
              " 'дар',\n",
              " 'зло',\n",
              " 'мно',\n",
              " 'тог',\n",
              " 'быт',\n",
              " 'даю',\n",
              " 'сло',\n",
              " 'теп',\n",
              " 'ост',\n",
              " 'бес',\n",
              " 'нег',\n",
              " 'чин',\n",
              " 'тою',\n",
              " 'хот',\n",
              " 'бек',\n",
              " 'бок',\n",
              " 'гол',\n",
              " 'жен',\n",
              " 'чей',\n",
              " 'вер',\n",
              " 'луч',\n",
              " 'нес',\n",
              " 'поч',\n",
              " 'вдр',\n",
              " 'жар',\n",
              " 'люб',\n",
              " 'опя',\n",
              " 'нож',\n",
              " 'ряд',\n",
              " 'вес',\n",
              " 'гла',\n",
              " 'дым',\n",
              " 'ход',\n",
              " 'всь',\n",
              " 'зла',\n",
              " 'неп',\n",
              " 'чуб',\n",
              " 'рту',\n",
              " 'слу',\n",
              " 'сны',\n",
              " 'чел',\n",
              " 'отв',\n",
              " 'сме',\n",
              " 'ник',\n",
              " 'пар',\n",
              " 'бил',\n",
              " 'есл',\n",
              " 'мал',\n",
              " 'оче',\n",
              " 'рта',\n",
              " 'уст',\n",
              " 'вед',\n",
              " 'кон',\n",
              " 'сия',\n",
              " 'баб',\n",
              " 'пов',\n",
              " 'рай',\n",
              " 'дум',\n",
              " 'дол',\n",
              " 'пра',\n",
              " 'сим',\n",
              " 'дне',\n",
              " 'зам',\n",
              " 'ива',\n",
              " 'име',\n",
              " 'нак',\n",
              " 'пом',\n",
              " 'поп',\n",
              " 'чьи',\n",
              " 'быв',\n",
              " 'дав',\n",
              " 'зол',\n",
              " 'пью',\n",
              " 'шеи',\n",
              " 'ниб',\n",
              " 'сер',\n",
              " 'лжи',\n",
              " 'соб',\n",
              " 'тип',\n",
              " 'шут',\n",
              " 'яко',\n",
              " 'бла',\n",
              " 'вре',\n",
              " 'дна',\n",
              " 'мил',\n",
              " 'нач',\n",
              " 'раб',\n",
              " 'чер',\n",
              " 'чья',\n",
              " 'нап',\n",
              " 'обр',\n",
              " 'сов',\n",
              " 'гос',\n",
              " 'идя',\n",
              " 'пел',\n",
              " 'пет',\n",
              " 'вос',\n",
              " 'ден',\n",
              " 'пал',\n",
              " 'све',\n",
              " 'спи',\n",
              " 'цел',\n",
              " 'бой',\n",
              " 'жиз',\n",
              " 'ищу',\n",
              " 'каж',\n",
              " 'пон',\n",
              " 'суп',\n",
              " 'хор',\n",
              " 'сле',\n",
              " 'лад',\n",
              " 'пир',\n",
              " 'сии',\n",
              " 'бед',\n",
              " 'зал',\n",
              " 'ура',\n",
              " 'але',\n",
              " 'зас',\n",
              " 'кра',\n",
              " 'мес',\n",
              " 'око',\n",
              " 'пус',\n",
              " 'ско',\n",
              " 'эге',\n",
              " 'выс',\n",
              " 'дер',\n",
              " 'рос',\n",
              " 'боя',\n",
              " 'зак',\n",
              " 'кол',\n",
              " 'оди',\n",
              " 'ото',\n",
              " 'пав',\n",
              " 'поз',\n",
              " 'смо',\n",
              " 'спр',\n",
              " 'тих',\n",
              " 'тож',\n",
              " 'заб',\n",
              " 'зав',\n",
              " 'лба',\n",
              " 'мел',\n",
              " 'отк',\n",
              " 'дно',\n",
              " 'зап',\n",
              " 'кня',\n",
              " 'люд',\n",
              " 'мат',\n",
              " 'мая',\n",
              " 'нед',\n",
              " 'пес',\n",
              " 'сос',\n",
              " 'уму',\n",
              " 'чье',\n",
              " 'веч',\n",
              " 'пис',\n",
              " 'уху',\n",
              " 'бар',\n",
              " 'вст',\n",
              " 'гул',\n",
              " 'ища',\n",
              " 'мер',\n",
              " 'наз',\n",
              " 'ром',\n",
              " 'сде',\n",
              " 'спа',\n",
              " 'ага',\n",
              " 'бро',\n",
              " 'доб',\n",
              " 'дов',\n",
              " 'зад',\n",
              " 'кри',\n",
              " 'тре',\n",
              " 'вод',\n",
              " 'ели',\n",
              " 'осо',\n",
              " 'пой',\n",
              " 'рев',\n",
              " 'вин',\n",
              " 'вру',\n",
              " 'дор',\n",
              " 'иск',\n",
              " 'лгу',\n",
              " 'лик',\n",
              " 'нич',\n",
              " 'ужа',\n",
              " 'щек',\n",
              " 'вол',\n",
              " 'дос',\n",
              " 'еле',\n",
              " 'зат',\n",
              " 'ино',\n",
              " 'лат',\n",
              " 'пла',\n",
              " 'пош',\n",
              " 'сор',\n",
              " 'бра',\n",
              " 'гру',\n",
              " 'заг',\n",
              " 'мин',\n",
              " 'нар',\n",
              " 'пож',\n",
              " 'сту',\n",
              " 'точ',\n",
              " 'хоч',\n",
              " 'дев',\n",
              " 'зря',\n",
              " 'меч',\n",
              " 'мыс',\n",
              " 'неу',\n",
              " 'сте',\n",
              " 'улы',\n",
              " 'зде',\n",
              " 'исп',\n",
              " 'кар',\n",
              " 'кро',\n",
              " 'кур',\n",
              " 'лай',\n",
              " 'лед',\n",
              " 'нав',\n",
              " 'нев',\n",
              " 'нео',\n",
              " 'нов',\n",
              " 'ока',\n",
              " 'пуф',\n",
              " 'реш',\n",
              " 'руб',\n",
              " 'сак',\n",
              " 'сок',\n",
              " 'тво',\n",
              " 'уха',\n",
              " 'вск',\n",
              " 'гам',\n",
              " 'ген',\n",
              " 'мед',\n",
              " 'наг',\n",
              " 'отд',\n",
              " 'рус',\n",
              " 'слы',\n",
              " 'взг',\n",
              " 'вой',\n",
              " 'воп',\n",
              " 'выш',\n",
              " 'дон',\n",
              " 'ешь',\n",
              " 'жел',\n",
              " 'зов',\n",
              " 'мук',\n",
              " 'неш',\n",
              " 'ниц',\n",
              " 'обс',\n",
              " 'оне',\n",
              " 'пря',\n",
              " 'сыр',\n",
              " 'уви',\n",
              " 'узн',\n",
              " 'худ',\n",
              " 'эка',\n",
              " 'взд',\n",
              " 'впе',\n",
              " 'гля',\n",
              " 'дуб',\n",
              " 'дур',\n",
              " 'ела',\n",
              " 'игр',\n",
              " 'изб',\n",
              " 'лиш',\n",
              " 'обл',\n",
              " 'ого',\n",
              " 'пей',\n",
              " 'пух',\n",
              " 'пят',\n",
              " 'ран',\n",
              " 'сла',\n",
              " 'тыс',\n",
              " 'укр',\n",
              " 'фед',\n",
              " 'фра',\n",
              " 'щоб',\n",
              " 'бей',\n",
              " 'бык',\n",
              " 'взя',\n",
              " 'гро',\n",
              " 'дво',\n",
              " 'жал',\n",
              " 'изв',\n",
              " 'куд',\n",
              " 'мух',\n",
              " 'ноч',\n",
              " 'пле',\n",
              " 'рак',\n",
              " 'ред',\n",
              " 'чег',\n",
              " 'чув',\n",
              " 'шея',\n",
              " 'бер',\n",
              " 'бор',\n",
              " 'вал',\n",
              " 'вме',\n",
              " 'глу',\n",
              " 'гоп',\n",
              " 'дет',\n",
              " 'док',\n",
              " 'ищи',\n",
              " 'кох',\n",
              " 'кре',\n",
              " 'нах',\n",
              " 'объ',\n",
              " 'ожи',\n",
              " 'тер',\n",
              " 'тро',\n",
              " 'тсс',\n",
              " 'уби',\n",
              " 'чет',\n",
              " 'эко',\n",
              " 'бел',\n",
              " 'быс',\n",
              " 'впр',\n",
              " 'зах',\n",
              " 'кру',\n",
              " 'мар',\n",
              " 'нек',\n",
              " 'нуж',\n",
              " 'поб',\n",
              " 'пог',\n",
              " 'рим',\n",
              " 'роз',\n",
              " 'соо',\n",
              " 'спо',\n",
              " 'сыт',\n",
              " 'тел',\n",
              " 'тра',\n",
              " 'уго',\n",
              " 'чес',\n",
              " 'юге',\n",
              " 'яму',\n",
              " 'бум',\n",
              " 'вез',\n",
              " 'воо',\n",
              " 'гра',\n",
              " 'жан',\n",
              " 'изд',\n",
              " 'кап',\n",
              " 'лех',\n",
              " 'отц',\n",
              " 'раю',\n",
              " 'ров',\n",
              " 'рты',\n",
              " 'сид',\n",
              " 'учи',\n",
              " 'вып',\n",
              " 'гад',\n",
              " 'жди',\n",
              " 'каз',\n",
              " 'кос',\n",
              " 'лез',\n",
              " 'мит',\n",
              " 'неб',\n",
              " 'отр',\n",
              " 'рок',\n",
              " 'рыб',\n",
              " 'сан',\n",
              " 'сек',\n",
              " 'сну',\n",
              " 'уве',\n",
              " 'уди',\n",
              " 'ухе',\n",
              " 'чад',\n",
              " 'чая',\n",
              " 'чис',\n",
              " 'чут',\n",
              " 'акт',\n",
              " 'вов',\n",
              " 'всп',\n",
              " 'дню',\n",
              " 'дул',\n",
              " 'ежа',\n",
              " 'жит',\n",
              " 'зем',\n",
              " 'злы',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "from nltk import edit_distance\n",
        "\n",
        "with open('./data/litw-win.txt', 'r', encoding=\"utf-8\") as f:\n",
        "  txt = f.read().split(\"\\n\")\n",
        "words = []\n",
        "for i in txt:\n",
        "  words.append(i.split()[-1])\n",
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_K-8m3FUsL3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b7fa92-f4d6-47ef-d797-1f3c00472f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "величайшим\n"
          ]
        }
      ],
      "source": [
        "word = \"велечайшим\"\n",
        "for w in words:\n",
        "  if edit_distance(word, w)==1:\n",
        "      print(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Bu2CDPVJsL3V"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "SnrDwXfgsL3V"
      },
      "outputs": [],
      "source": [
        "text = '''с велечайшим усилием выбравшись из потока убегающих людей Кутузов со свитой уменьшевшейся вдвое поехал на звуки выстрелов русских орудий'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyLIdMZ9sL3V",
        "outputId": "e95b9d90-dd40-49e5-8dc5-eaa8ecb4b4a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "edit_distance(\"из\",'ис')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTGhU2c5sL3W",
        "outputId": "f8e37c41-0768-495b-ccff-4d611bb05a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['с', 'величайшим', 'усилиям', 'выбрившись', 'из', 'потомка', 'убегающим', 'люден', 'кутузов', 'со', 'свиткой', 'уменьшившейся', 'вдвоем', 'поехало', 'на', 'звуко', 'выстрелив', 'прусских', 'орудуй']\n"
          ]
        }
      ],
      "source": [
        "splitText = re.split('\\W+', text)\n",
        "for index,s in  enumerate(splitText):\n",
        "  for w in words:\n",
        "    if edit_distance(s, w)==1 and len(s)>2:\n",
        "      splitText[index] = w\n",
        "\n",
        "print(splitText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6OtGmIsL3W"
      },
      "source": [
        "2. Разбейте текст из формулировки задания 1 на слова; проведите стемминг и лемматизацию слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ToOAuUKmsL3W"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk import word_tokenize\n",
        "import pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Sd9gfiofsL3W"
      },
      "outputs": [],
      "source": [
        "text = '''Разбейте текст из формулировки второго задания на слова. Проведите стемминг и лемматизацию слов.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "PtNraUZrsL3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8950e6-c92a-46b5-8b0d-0f18d8a7c1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['велечайшим']\n"
          ]
        }
      ],
      "source": [
        "a = word_tokenize(word)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UdbDQKTjsL3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0774e406-300d-4ce6-88ed-5fd75affaab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "разб\n",
            "текст\n",
            "из\n",
            "формулировк\n",
            "втор\n",
            "задан\n",
            "на\n",
            "слов\n",
            ".\n",
            "провед\n",
            "стемминг\n",
            "и\n",
            "лемматизац\n",
            "слов\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "stemmer = SnowballStemmer('russian')\n",
        "for wordss in word_tokenize(text):\n",
        "    print(stemmer.stem(wordss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "wls93JC2sL3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ee4970-d36f-4c13-c9a6-2b321e5dd772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "разбить\n",
            "текст\n",
            "из\n",
            "формулировка\n",
            "второй\n",
            "задание\n",
            "на\n",
            "слово\n",
            ".\n",
            "провести\n",
            "стемминг\n",
            "и\n",
            "лемматизация\n",
            "слово\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "for wordss in word_tokenize(text):\n",
        "    print(morph.parse(wordss)[0].normalized.word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXXL4-ESsL3X"
      },
      "source": [
        "3. Преобразуйте предложения из формулировки задания 1 в векторы при помощи `CountVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "N9sq3YGrsL3X"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GdENpmEVsL3X"
      },
      "outputs": [],
      "source": [
        "text = '''Разбейте текст из формулировки второго задания на слова. Проведите стемминг и лемматизацию слов.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "BNjtbHKAsL3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0445a6-f663-434b-96b1-9a1e73d83661"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 12),\n",
              " array([[1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
              "        [0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "cv = CountVectorizer()\n",
        "cv.fit(sent_tokenize(text))\n",
        "sents_cv=cv.transform(sent_tokenize(text)).toarray()\n",
        "sents_cv.shape, sents_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Lh-ueDmDsL3Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2d9ac1-b509-47fd-c893-d40ba8411863"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'разбейте': 6,\n",
              " 'текст': 10,\n",
              " 'из': 2,\n",
              " 'формулировки': 11,\n",
              " 'второго': 0,\n",
              " 'задания': 1,\n",
              " 'на': 4,\n",
              " 'слова': 8,\n",
              " 'проведите': 5,\n",
              " 'стемминг': 9,\n",
              " 'лемматизацию': 3,\n",
              " 'слов': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "cv.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTSswjhysL3Y"
      },
      "source": [
        "## Лабораторная работа 9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rEm8zBv0O4uX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iGgLmqssL3Y"
      },
      "source": [
        "### Расстояние редактирования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZVtzVLhsL3Y"
      },
      "source": [
        "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./data/preprocessed_descriptions.csv', delimiter=',', parse_dates=[\"submitted\"])\n",
        "\n",
        "descriptions = data[\"description\"].fillna(\"\")\n",
        "unique_words = []\n",
        "\n",
        "for description in descriptions:\n",
        "  tokens = word_tokenize(description)\n",
        "  unique_words.extend(set(tokens))\n",
        "\n",
        "# Преобразование списка уникальных слов в множество, чтобы удалить дубликаты, и обратно в список\n",
        "unique_words = list(set(unique_words))\n",
        "\n",
        "unique_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2QVgxgBOhx9",
        "outputId": "5d9ecafd-00e3-49a6-9156-45353e675940"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fry-pan',\n",
              " 'crehan',\n",
              " 'coal-burning',\n",
              " 'thidabeau',\n",
              " 'parragon',\n",
              " 'trolly',\n",
              " 'before',\n",
              " '135158',\n",
              " 'bounty',\n",
              " 'clonakilty',\n",
              " 'omnivores',\n",
              " '87173',\n",
              " 'lex',\n",
              " 'rubbermaid',\n",
              " 'geaux',\n",
              " 'suzanne',\n",
              " 'tarka',\n",
              " 'frustrated',\n",
              " 'grandson',\n",
              " \"'finger\",\n",
              " 'pero',\n",
              " \"'sticks\",\n",
              " 'sautéed',\n",
              " 'bobbie',\n",
              " 'best.',\n",
              " 'induce',\n",
              " '141',\n",
              " 'entrees',\n",
              " 'minimize',\n",
              " 'marlboro',\n",
              " 'corners',\n",
              " 'morsels',\n",
              " 'tight-fitting',\n",
              " 'syrp',\n",
              " 'concoct',\n",
              " 'bethenny',\n",
              " 'foriegn',\n",
              " 'unders',\n",
              " 'sirop',\n",
              " 'ahora',\n",
              " 'coriander',\n",
              " 'long-handled',\n",
              " 'spices.the',\n",
              " 'e.d',\n",
              " 'sais',\n",
              " \"'10\",\n",
              " 'exsisted',\n",
              " 'tracks',\n",
              " 'embosses',\n",
              " 'following',\n",
              " 'chile-',\n",
              " '255532',\n",
              " '1947.',\n",
              " '362382',\n",
              " 'small-batch',\n",
              " 'needing',\n",
              " '//www.foodlushblog.com/2011/03/recipe-knockoff-campbells-bean-with-bacon-soup.html',\n",
              " 'clothes',\n",
              " \"don't/\",\n",
              " 'tryed',\n",
              " 'british/jewish',\n",
              " 'overloaded',\n",
              " 'welltellme.com',\n",
              " 'activities',\n",
              " 'bosley',\n",
              " 'allow',\n",
              " '526666',\n",
              " 'ran',\n",
              " 'rossipasta.com',\n",
              " '1912',\n",
              " 'nervous',\n",
              " 'menthe',\n",
              " \"'summer\",\n",
              " 'spouse',\n",
              " 'cheesesticks',\n",
              " 'wy',\n",
              " 'sugarholic',\n",
              " 'sliders',\n",
              " 'bread.if',\n",
              " 'goats',\n",
              " 'status',\n",
              " 'temperature/humidity',\n",
              " '102933',\n",
              " 'wavy',\n",
              " 'stories',\n",
              " 'amung',\n",
              " 'grossinger',\n",
              " 'jiaotze',\n",
              " 'mandarine',\n",
              " '225',\n",
              " 'licorice',\n",
              " '470',\n",
              " 'dynamite',\n",
              " 'sleepyheads',\n",
              " 'yukon',\n",
              " 'rocca',\n",
              " 'kalbi',\n",
              " 'cremier',\n",
              " 'growing.remember',\n",
              " 'kemp',\n",
              " 'forewarned',\n",
              " 'album',\n",
              " '504523',\n",
              " 'users',\n",
              " 'oui',\n",
              " 'veggie',\n",
              " 'wing-time',\n",
              " 'dawn',\n",
              " 'listed',\n",
              " 'butternuts',\n",
              " 'stabbing',\n",
              " 'norway-hei.com',\n",
              " 'bouillabaisse',\n",
              " 'graduated',\n",
              " 'htipiti',\n",
              " 'napalm',\n",
              " 'starchier',\n",
              " \"'sandra\",\n",
              " 'fluted',\n",
              " 'gardens,10/2007',\n",
              " 'yen',\n",
              " 'ranhofer',\n",
              " 'suggests',\n",
              " 'make-over',\n",
              " 'dannenberg',\n",
              " 'nonetheless',\n",
              " 'fingertips.prep',\n",
              " '2.13',\n",
              " 'imparted',\n",
              " '454028',\n",
              " 'war-time',\n",
              " 'olives',\n",
              " 'rabbit',\n",
              " 'payard',\n",
              " 'col',\n",
              " 'daytime',\n",
              " 'adobe',\n",
              " 'cilnatro',\n",
              " 'amazingly',\n",
              " 'prize-winning',\n",
              " 'a,9',\n",
              " 'pattern',\n",
              " 's/h',\n",
              " 'totmato',\n",
              " 'rates',\n",
              " 'pirello',\n",
              " 'v8',\n",
              " 'hamtramck',\n",
              " '75548',\n",
              " 'australia',\n",
              " '//www.chinesefooddiy.com/lowfat_eggplant_garlic_sauce.htm',\n",
              " 'france',\n",
              " 'off-the-shelf',\n",
              " '67mg',\n",
              " 'kentucky',\n",
              " 'attend',\n",
              " '1/4',\n",
              " 'tongue',\n",
              " 'non-red',\n",
              " 'faboulous',\n",
              " 'guidetti',\n",
              " 'blossoms',\n",
              " '200.00',\n",
              " '100g',\n",
              " 'district',\n",
              " 'gain',\n",
              " 'crabapples',\n",
              " 'payoff',\n",
              " 'writes',\n",
              " 'mon',\n",
              " 'caramelizing',\n",
              " 'iime',\n",
              " '8/08',\n",
              " 'decandant',\n",
              " 'individual',\n",
              " 'cooking.com',\n",
              " '475073',\n",
              " 'true-',\n",
              " 'basis-',\n",
              " 'gai',\n",
              " 'cookbook.-heritage',\n",
              " 'designated',\n",
              " 'cruff',\n",
              " 're-entry',\n",
              " 'smoothies',\n",
              " 'cervelat',\n",
              " '35cm',\n",
              " 'casbah',\n",
              " 'encouraging',\n",
              " 'hospital',\n",
              " 'undertaste',\n",
              " 'sherri',\n",
              " 'four-year-old',\n",
              " 'mistress',\n",
              " 'flipping',\n",
              " 'farina',\n",
              " 'soo',\n",
              " 'pittsburgh',\n",
              " 'murphy',\n",
              " '2013.',\n",
              " 'ribs',\n",
              " 'issue',\n",
              " '427810',\n",
              " 'www.cookiesfromitaly.com',\n",
              " \"'back\",\n",
              " 'good-good-good',\n",
              " 'b.b.q.',\n",
              " 'mania',\n",
              " 'vouch',\n",
              " 'soup/stew',\n",
              " 'flat-bread',\n",
              " '1,000,000',\n",
              " 'dealer',\n",
              " 'rosa',\n",
              " 'surviving',\n",
              " 'cruise',\n",
              " 'hogmanay-',\n",
              " '26877',\n",
              " 'gin',\n",
              " 'kerali',\n",
              " 'roar',\n",
              " 'refreshment',\n",
              " 'enliven',\n",
              " 'groom',\n",
              " '10-tortilla',\n",
              " 'divinity',\n",
              " 'philadelphians',\n",
              " 'bucks',\n",
              " 'after-dinner',\n",
              " 'easlily',\n",
              " 'statement',\n",
              " 'vietnamese/thai',\n",
              " 'stanton',\n",
              " 'it-not',\n",
              " 'collect',\n",
              " \"s'mores\",\n",
              " 'elegant-looking',\n",
              " '1009/january',\n",
              " 'call',\n",
              " 'fights',\n",
              " 'genevieve',\n",
              " 'disclaimer',\n",
              " 'tast',\n",
              " 'hedge',\n",
              " 'assures',\n",
              " 't.g.i',\n",
              " 'hey',\n",
              " 'centres',\n",
              " 'abide',\n",
              " '47mg',\n",
              " 'quick/1min',\n",
              " 'estonia',\n",
              " 'submerge',\n",
              " 'msn',\n",
              " 'rubbed',\n",
              " 'tumbler',\n",
              " 'stabilizes',\n",
              " \"'winter\",\n",
              " 'sunny-side-up',\n",
              " 'deglaze',\n",
              " 'wear',\n",
              " 'michy',\n",
              " 'nuclear',\n",
              " 'fontaine',\n",
              " 'east',\n",
              " 'irresistible.enjoy',\n",
              " 'mortar-like',\n",
              " 'ready-made',\n",
              " 'parmenter',\n",
              " 'riomaggiore',\n",
              " 'lingonberries',\n",
              " 'bake',\n",
              " '.....',\n",
              " 'determine',\n",
              " 'used.also',\n",
              " 'sauce/gravy',\n",
              " 'dbmnmr',\n",
              " 'focused',\n",
              " 'utm_medium=twitter',\n",
              " 'diminished',\n",
              " 'daisy',\n",
              " 'youngest',\n",
              " 'counted',\n",
              " 'shortbread',\n",
              " 'fend',\n",
              " '2002',\n",
              " 'twenties',\n",
              " 'wishes',\n",
              " \"'guinea\",\n",
              " 'godairyfree.com',\n",
              " 'write',\n",
              " 'stalks',\n",
              " '114732',\n",
              " 'pushcarts',\n",
              " 'sours',\n",
              " 'patoot',\n",
              " 'wou',\n",
              " 'thank-you',\n",
              " 'porto',\n",
              " \"'mrs\",\n",
              " 'candied',\n",
              " 'panna',\n",
              " 'www.funkymunky.co.za/african.html',\n",
              " 'goji',\n",
              " 'softens',\n",
              " 'siblings',\n",
              " 'cleansing',\n",
              " 'feijoas',\n",
              " 'hasa',\n",
              " 'hillshire',\n",
              " 'ro-tel',\n",
              " '1.4kg',\n",
              " 'stinking',\n",
              " '.-',\n",
              " 'manchego',\n",
              " 'pimientos',\n",
              " 'potroast',\n",
              " 'comes',\n",
              " 'squeze',\n",
              " 'adventure',\n",
              " 'beef/pork',\n",
              " '2.4g',\n",
              " 'supportive',\n",
              " 'creat',\n",
              " 'norfolk',\n",
              " 'chef-i-am',\n",
              " 'coffeecake',\n",
              " 'meals.com',\n",
              " \"'try\",\n",
              " 'spritzer',\n",
              " \"linda'sbusykitchen\",\n",
              " 'legally',\n",
              " 'elsewhere',\n",
              " 'liquid-y',\n",
              " '2/serving',\n",
              " 'rodgers',\n",
              " 'payne',\n",
              " '1/2-1',\n",
              " 'somen/soba',\n",
              " 'biltong',\n",
              " 'agreeable',\n",
              " 'chiarello',\n",
              " 'wolfert',\n",
              " 'nanner',\n",
              " 'lynne',\n",
              " 'dot',\n",
              " 'interchange',\n",
              " \"productions'cookbook\",\n",
              " 'guinna',\n",
              " 'australian',\n",
              " 'moreover',\n",
              " 'hairdresser',\n",
              " 'vats',\n",
              " 'sbd',\n",
              " 'deformed',\n",
              " 'rubber',\n",
              " 'inclusion',\n",
              " 'diwali',\n",
              " 'imparting',\n",
              " 'joins',\n",
              " 'oakshire',\n",
              " 'bottomless',\n",
              " 'no-holds-barred',\n",
              " 'tiffin',\n",
              " 'paneer',\n",
              " 'repeatedly',\n",
              " 'spices',\n",
              " 'cooksrecipes.com',\n",
              " 'baguette',\n",
              " \"'dry\",\n",
              " 'roberto',\n",
              " 'cost-cutting',\n",
              " 'j/a',\n",
              " 'halves',\n",
              " 'eatons',\n",
              " '70s',\n",
              " 'circa',\n",
              " 'prunes',\n",
              " 'rsc8',\n",
              " 'chicken/pasta',\n",
              " 'frowns',\n",
              " 'cheese-cake',\n",
              " 'family-friendly',\n",
              " 'arnotts',\n",
              " 'calling',\n",
              " 'isabel',\n",
              " 'hum',\n",
              " 'ford',\n",
              " 'transfer',\n",
              " 'disposable',\n",
              " 'choix',\n",
              " 'favorably',\n",
              " 'ditto',\n",
              " 'beside',\n",
              " '01/02/2008',\n",
              " 'chrisp',\n",
              " 'sandwich.a',\n",
              " 'rewritten',\n",
              " 'cubed',\n",
              " 'saltier',\n",
              " 'gems',\n",
              " 'size-down.i',\n",
              " 'times.its',\n",
              " 'administration',\n",
              " 'date-night-in',\n",
              " '325°f',\n",
              " 'spongy',\n",
              " 'hehehe',\n",
              " 'regimen',\n",
              " 'decidely',\n",
              " 'breakfast.submitted',\n",
              " 'y-e-l-l-s',\n",
              " 'carve',\n",
              " 'caterer',\n",
              " 'this-there',\n",
              " 'swati',\n",
              " 'creator',\n",
              " \"'n\",\n",
              " 'smokey',\n",
              " 'tollhouse',\n",
              " 'nichole',\n",
              " 'genovese',\n",
              " 'glutenfreeda.com',\n",
              " 'demand',\n",
              " 'vegs',\n",
              " 'malay',\n",
              " 'rides',\n",
              " 'necks',\n",
              " 'luckily',\n",
              " 'grunzig',\n",
              " 'drover',\n",
              " 'g',\n",
              " 're-heat',\n",
              " 'lakeway',\n",
              " 'back',\n",
              " 'useing',\n",
              " 'happily',\n",
              " 'august/september',\n",
              " 'manually',\n",
              " '45°',\n",
              " 'chappatis',\n",
              " 'hunanese',\n",
              " 'bavarians',\n",
              " 'wet',\n",
              " 'anemic',\n",
              " 'microgreens',\n",
              " 'emailed',\n",
              " 'bajillion',\n",
              " 'monastery',\n",
              " 'human',\n",
              " 'steak-fest',\n",
              " 'daytona',\n",
              " \"'real\",\n",
              " 'trimeseter',\n",
              " 'probaly',\n",
              " '9x5-inch',\n",
              " 'macadamia',\n",
              " 'strewn',\n",
              " 'shelters',\n",
              " '1.76',\n",
              " 'duo',\n",
              " 'texture.by',\n",
              " 'loaned',\n",
              " 'journey',\n",
              " '07',\n",
              " 'happenings',\n",
              " 'floating',\n",
              " 'vegatarian',\n",
              " 'chatted',\n",
              " 'stock',\n",
              " 'moistness',\n",
              " 'duper',\n",
              " 'meaty',\n",
              " 'willing',\n",
              " 'satés',\n",
              " 'youtube',\n",
              " 'johsonville',\n",
              " 'foam',\n",
              " 'magic',\n",
              " '180',\n",
              " 'cuban-style-cut',\n",
              " 'koval',\n",
              " 'complete',\n",
              " 'election',\n",
              " 'shortcake',\n",
              " 'sticky',\n",
              " 'susannah',\n",
              " 'scandinavia',\n",
              " 'piped',\n",
              " 'reserving',\n",
              " 'herbamare',\n",
              " 'toresini',\n",
              " 'naughty',\n",
              " 'paddy',\n",
              " 'gobble',\n",
              " 'pansies',\n",
              " 'everybody',\n",
              " 'post-worthy',\n",
              " 'femina',\n",
              " 'thomas',\n",
              " 'kingsolver',\n",
              " 'slovak-american',\n",
              " '5/4/08',\n",
              " 'grisanti',\n",
              " 'spiffed-up',\n",
              " 'cake-like',\n",
              " 'triangles',\n",
              " 'high-riser',\n",
              " 'disinclined',\n",
              " 'drastically',\n",
              " \"'whole-grain\",\n",
              " 'splurge',\n",
              " 'blondie',\n",
              " 'tremendously',\n",
              " 'ingredient',\n",
              " 'cheap',\n",
              " 'mimic',\n",
              " 'reef',\n",
              " 'honoring',\n",
              " 'shicken',\n",
              " 'rice-sized',\n",
              " 'cherish',\n",
              " 'rice-',\n",
              " 'czechoslovak',\n",
              " 'void',\n",
              " '70mg',\n",
              " '75401',\n",
              " 'bread/butter',\n",
              " 'eleanor',\n",
              " 'moberly',\n",
              " 'unfortunatly',\n",
              " 'envious',\n",
              " 'double-baked',\n",
              " '8mg',\n",
              " 'most-requested',\n",
              " 'forgets',\n",
              " 'concession',\n",
              " 'vivette',\n",
              " 'prossessor',\n",
              " '89007',\n",
              " 'cookshelf',\n",
              " 'pinks',\n",
              " \"'pesto\",\n",
              " 'hither',\n",
              " 'pre-cook',\n",
              " 'joes',\n",
              " 'much-loved',\n",
              " 'adult',\n",
              " 'home/simple',\n",
              " '12oz',\n",
              " 'ham-and',\n",
              " 'style.i',\n",
              " 'africas',\n",
              " 'pies/cookies/sweet',\n",
              " 'lemon-garlic',\n",
              " 'boozy',\n",
              " 'cholesterol-reduction',\n",
              " 'family/our',\n",
              " 'nielsen',\n",
              " 'blew',\n",
              " 'work-intensive',\n",
              " 'mousses',\n",
              " 'heartwarming',\n",
              " 'process',\n",
              " 'kimchee',\n",
              " 'chanterelles',\n",
              " 'yummm',\n",
              " 'jerod',\n",
              " 'artful',\n",
              " 'harb',\n",
              " '300.',\n",
              " 'guesstimating',\n",
              " '1t',\n",
              " 'budgeting',\n",
              " 'sour/sweet',\n",
              " 'pampered',\n",
              " 'reccomends',\n",
              " 'popularity.lily',\n",
              " 'nov',\n",
              " 'danny',\n",
              " 'consuming',\n",
              " 'weed',\n",
              " 'viatmin',\n",
              " 'well-',\n",
              " 've',\n",
              " 'flowed',\n",
              " 'unbaked',\n",
              " '9/06',\n",
              " '//www.24hourmom.com',\n",
              " 'gustafson',\n",
              " 'carfabas',\n",
              " 'bevcooks.com',\n",
              " 'israel-food',\n",
              " 'trendiest',\n",
              " '//bit.ly/7bwgul',\n",
              " '01/06/1991',\n",
              " 'canth',\n",
              " 'brendan',\n",
              " 'reading',\n",
              " \"'klevo\",\n",
              " 'boo',\n",
              " '//domesticaffair.blogspot.com/2005/04/simply-sweet.html',\n",
              " 'thiel',\n",
              " 'responsibly',\n",
              " 'rhythmic',\n",
              " 'lordy',\n",
              " 'no-cholesterol',\n",
              " 'chex.com',\n",
              " 'w/bacon',\n",
              " 'emilia-romagna',\n",
              " 'unpredictability',\n",
              " '1952.',\n",
              " 'brined',\n",
              " 'hand-hope',\n",
              " '//misslemonie.wordpress.com/2010/12/20/the-naughty-the-nice/',\n",
              " 'recognizing',\n",
              " 'joke',\n",
              " 'towns',\n",
              " 'ginsbergs',\n",
              " 'let',\n",
              " 'ml',\n",
              " 'slim',\n",
              " 'thinking',\n",
              " 'unto',\n",
              " 'lbs.',\n",
              " 'metabolism-raising',\n",
              " 'bhg.com',\n",
              " 'herbal',\n",
              " 'ourbestbites.com',\n",
              " 'bike',\n",
              " 'redhot',\n",
              " 'tucson',\n",
              " 'jelly',\n",
              " 'over-stuffed',\n",
              " 'bad-biscuit',\n",
              " 'historically',\n",
              " '¼',\n",
              " 'sometime',\n",
              " 'thickener',\n",
              " 'schlabberkappes',\n",
              " 'filmed',\n",
              " 'cannister',\n",
              " 'expiration',\n",
              " 'beginning',\n",
              " 'evidently',\n",
              " 'carte',\n",
              " 'peking',\n",
              " 'sadly',\n",
              " '80′s',\n",
              " 'swedish',\n",
              " 'decade',\n",
              " 'carotenes',\n",
              " 'hot-as-you-want-it',\n",
              " 'kale',\n",
              " 'impera_magna',\n",
              " 'dee',\n",
              " '250-265',\n",
              " '175757.',\n",
              " 'cynthia',\n",
              " \"'tales\",\n",
              " 'crinkly',\n",
              " 'baciare',\n",
              " 'caroline',\n",
              " 'vanderbilt',\n",
              " 'mushooms',\n",
              " 'belive',\n",
              " 'huuuuuge',\n",
              " 'jibarito',\n",
              " 'stronger-tasting',\n",
              " 'rv',\n",
              " 'whistlestop',\n",
              " 'unstead',\n",
              " 'cal/low',\n",
              " 'chatting',\n",
              " 'www.tienda.com',\n",
              " 'cosmos',\n",
              " 'pinch',\n",
              " 'scrubbing',\n",
              " 'prompted',\n",
              " 'nevermore',\n",
              " 'tube/bag',\n",
              " 'albi',\n",
              " 'sacrificing',\n",
              " 'dieters',\n",
              " 'williamsburg',\n",
              " 'incuded',\n",
              " 'sombreros',\n",
              " 'water-soaked',\n",
              " 'peg',\n",
              " 'health-edit',\n",
              " 'jones',\n",
              " 'grinka',\n",
              " 'vegas',\n",
              " '13-month-old',\n",
              " 'tattered',\n",
              " 'big-time',\n",
              " 'soufflé',\n",
              " 'hcg',\n",
              " 'vegetables-',\n",
              " 'thumbs',\n",
              " 'diego',\n",
              " 'accomidate',\n",
              " 'anaheim',\n",
              " 'munchie',\n",
              " 'foodtv',\n",
              " 'worchester',\n",
              " 'paraphrased',\n",
              " 'lüchowï¿½s',\n",
              " 'non-acidic',\n",
              " 'washing',\n",
              " 'contribution',\n",
              " 'pulverized',\n",
              " 'emulsifiers',\n",
              " 'surround',\n",
              " 'mocha',\n",
              " 'beta',\n",
              " 'skateboarder',\n",
              " 'notice',\n",
              " 'thai-type',\n",
              " 'pre-cooked',\n",
              " 'www.bawarchi.com',\n",
              " 'lastest',\n",
              " 'intrigued',\n",
              " 'vorous',\n",
              " 'testimonials',\n",
              " 'saabut',\n",
              " 'store/market',\n",
              " 'sunita',\n",
              " 'mini-ham',\n",
              " 'specialties',\n",
              " '2003-2004',\n",
              " 'shank',\n",
              " 'variation',\n",
              " 'calrose',\n",
              " 'wyler',\n",
              " 'blahs',\n",
              " 'mezze',\n",
              " 'form.i',\n",
              " 'castilla-leon',\n",
              " 'kijima',\n",
              " 'chase',\n",
              " 'up.it',\n",
              " 'dairy-eating',\n",
              " 'steamer/rice',\n",
              " 't=261947',\n",
              " 'molinillo',\n",
              " '38782',\n",
              " '6/15/07',\n",
              " 'amusing',\n",
              " 'relieving',\n",
              " 'sufferer',\n",
              " 'florets',\n",
              " '452940',\n",
              " 'dressings',\n",
              " 'ritchie',\n",
              " 'let-me-tell-you',\n",
              " 'beef…but',\n",
              " 'regarded',\n",
              " 'preheating',\n",
              " 'lines',\n",
              " 'healthified',\n",
              " 'attraction',\n",
              " 'workablity',\n",
              " 'gapultos',\n",
              " 'snacking',\n",
              " 'reciepe',\n",
              " 'appetizing',\n",
              " 'campbell',\n",
              " 'neirmann',\n",
              " 'conwell',\n",
              " 'reuben',\n",
              " 'networ',\n",
              " 'store.i',\n",
              " 'petite',\n",
              " 'purchase',\n",
              " 'forest',\n",
              " 'found',\n",
              " 'african-american',\n",
              " 'etc',\n",
              " 'grecian-style',\n",
              " '1994.',\n",
              " 'either',\n",
              " 'inclined',\n",
              " 'aliza',\n",
              " 'reech',\n",
              " 'tough',\n",
              " 'mornay',\n",
              " 'dahl',\n",
              " 'definate',\n",
              " 'allthingsnice',\n",
              " 'jacobseon',\n",
              " '3,3,3',\n",
              " 'trademarked',\n",
              " 'sorority',\n",
              " 'appearances',\n",
              " 'braidwoods',\n",
              " 'butterless',\n",
              " '17415',\n",
              " 'salvadorian',\n",
              " 'kneidlach',\n",
              " 'puff',\n",
              " 'aberdeen',\n",
              " 'side…',\n",
              " 'allergic',\n",
              " 'preggers',\n",
              " 'phenominal',\n",
              " 'demonstrate',\n",
              " 'centuries',\n",
              " 'conditioned',\n",
              " 'copies',\n",
              " 'figured',\n",
              " '1950s',\n",
              " 'speaks',\n",
              " 'lassi',\n",
              " 'echo',\n",
              " 'waffle',\n",
              " 'victims',\n",
              " '.............',\n",
              " 'donnellan',\n",
              " 'clafoutis',\n",
              " 'smokiness',\n",
              " 'waaay',\n",
              " 'sears',\n",
              " 'lost',\n",
              " 'carb/low',\n",
              " 'wahlgren',\n",
              " 'dib',\n",
              " 'brief',\n",
              " 'o.k',\n",
              " 'indonesian',\n",
              " 'featuring',\n",
              " 'definately',\n",
              " 'attempts',\n",
              " 'line-caught',\n",
              " 'kurma',\n",
              " 'terrace',\n",
              " 'hates',\n",
              " 'restorative',\n",
              " 'heaven',\n",
              " '2007/nov',\n",
              " 'dupree',\n",
              " 'wang',\n",
              " '325f',\n",
              " 'doneness',\n",
              " 'mace',\n",
              " 'springform',\n",
              " '//www.recipezaar.com/pineapple-upside-down-cake-408537',\n",
              " 'pla',\n",
              " 'ashbury',\n",
              " 'haminados',\n",
              " 'soy-cheese',\n",
              " 'grassroots',\n",
              " 'disk',\n",
              " 'sandwich/panini',\n",
              " 'conclusion',\n",
              " 'trego',\n",
              " 'holder',\n",
              " \"'salad\",\n",
              " 'gherkins',\n",
              " 'position',\n",
              " '261412.',\n",
              " 'steakhouses',\n",
              " 'candlelight',\n",
              " 'seasonings.and',\n",
              " 'guests.it',\n",
              " 'despise',\n",
              " 'soothing',\n",
              " '1-3',\n",
              " 'chop/cry',\n",
              " '409958',\n",
              " 'allstar',\n",
              " 'marteal',\n",
              " 'hefty',\n",
              " 'apple-smoked',\n",
              " 'tammie',\n",
              " 'edinburgh',\n",
              " 'octoberfest',\n",
              " 'bravas',\n",
              " 'themselves',\n",
              " 'releases',\n",
              " \"'flavour\",\n",
              " 'spread/salad/side-dish',\n",
              " 'equivelant',\n",
              " 'fields',\n",
              " 'germ-it',\n",
              " 'potlucks',\n",
              " 'balanced',\n",
              " 'splenda',\n",
              " 'ale',\n",
              " 'galestro',\n",
              " '170',\n",
              " 'chefpaul.com',\n",
              " 'nutella',\n",
              " 'aspects',\n",
              " 'rivers',\n",
              " 'vancouver',\n",
              " '3/4',\n",
              " 'tourists',\n",
              " 'greenlee',\n",
              " 'battered',\n",
              " 'adodpted',\n",
              " 'orange-red',\n",
              " 'nimz',\n",
              " 'hope',\n",
              " 'share',\n",
              " 'describe',\n",
              " 'greasy',\n",
              " 'rowed',\n",
              " 'cringed',\n",
              " 'mold',\n",
              " 'employer',\n",
              " 'washcloth',\n",
              " '36-40',\n",
              " '93',\n",
              " 'pta',\n",
              " 'spareribs',\n",
              " 'races',\n",
              " '10/24/15',\n",
              " 'herrings',\n",
              " 'adorned',\n",
              " 'oversize',\n",
              " 'bernstein-martinez',\n",
              " 'guinness',\n",
              " 'comapny',\n",
              " 'nigerian',\n",
              " 'heritage',\n",
              " 'mrbreakfast.com',\n",
              " 'foil-packet',\n",
              " 'chavich',\n",
              " 'rotis',\n",
              " 'wizard',\n",
              " '3/4-inch',\n",
              " 'bowls',\n",
              " 'spanish',\n",
              " 'pichet',\n",
              " \"t'aint\",\n",
              " '160',\n",
              " 'gloppy',\n",
              " '1/2',\n",
              " 'cheese-yum',\n",
              " 'hokkien',\n",
              " 'kabbage',\n",
              " 'bistec',\n",
              " 'skewed',\n",
              " 'carters',\n",
              " 'remade',\n",
              " 'grill™',\n",
              " 'jillian',\n",
              " 'endeavors',\n",
              " 'units',\n",
              " '364735',\n",
              " 'industrially-grown',\n",
              " 'heaping',\n",
              " 'arsenic',\n",
              " 'pappadums',\n",
              " 'omelette/frittatas',\n",
              " 'boomette',\n",
              " 'id=93705',\n",
              " 'serrano',\n",
              " '2-hour',\n",
              " 'ultimately',\n",
              " 'brown-colored',\n",
              " '144905',\n",
              " 'inch',\n",
              " 'loser',\n",
              " 'mitzi',\n",
              " 'bambara',\n",
              " 'popped',\n",
              " 'mailny',\n",
              " 'casual',\n",
              " 'hermes',\n",
              " '2.40',\n",
              " 'hawker',\n",
              " 'brayon',\n",
              " 'sour',\n",
              " 'brown-eyed',\n",
              " 'spread.these',\n",
              " 'fredricksburg',\n",
              " 'b-6',\n",
              " 'pierre',\n",
              " 'easy-to-make',\n",
              " 'austrian',\n",
              " 'rustic',\n",
              " 'earn',\n",
              " 'w/boiled',\n",
              " 'occurred',\n",
              " 'concerning',\n",
              " '17126',\n",
              " 'cherry-black',\n",
              " 'embarrassed',\n",
              " 'hoosier',\n",
              " 'packets',\n",
              " 'proudly',\n",
              " 'buenos',\n",
              " 'littleton',\n",
              " '48835',\n",
              " 'commenter',\n",
              " 'pamela',\n",
              " 'lsu',\n",
              " 'w-s',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew1f6PbAsL3Y"
      },
      "source": [
        "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "5f57dloXRmEK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_word_pairs = random.sample(unique_words, 10)\n",
        "\n",
        "for i in range(0, len(random_word_pairs), 2):\n",
        "  word1 = random_word_pairs[i]\n",
        "  word2 = random_word_pairs[i+1]\n",
        "  distance = edit_distance(word1, word2)\n",
        "  print(f\"Расстояние редактирования между '{word1}' и '{word2}': {distance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUUZOORoRWpc",
        "outputId": "47c8c63e-c1b5-4e5f-ac7f-850845bdbcea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Расстояние редактирования между 'pureed' и 'taste-a-like': 11\n",
            "Расстояние редактирования между 'this-but' и 'autism': 7\n",
            "Расстояние редактирования между 'informations' и 'headed': 11\n",
            "Расстояние редактирования между 'superbly' и 'justine': 7\n",
            "Расстояние редактирования между 'penetrate' и 'www.thaifoodandtravel.com': 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHe-D1ssL3Y"
      },
      "source": [
        "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_k_nearest_words(word, words, k=5):\n",
        "  sorted_words = sorted(words, key=lambda w: edit_distance(word, w))\n",
        "  return sorted_words[:k]\n",
        "\n",
        "word = \"данные\"\n",
        "k_nearest = find_k_nearest_words(word, words)\n",
        "k_nearest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEkXnEKoUUy9",
        "outputId": "46c447cf-90c8-4249-bb69-081a490ad934"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['данные', 'данное', 'данных', 'данным', 'данный']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1fcefNrsL3Z"
      },
      "source": [
        "### Стемминг, лемматизация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JahCC13vsL3Z"
      },
      "source": [
        "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами:\n",
        "*   word\n",
        "*   stemmed_word\n",
        "*   normalized_word\n",
        "\n",
        "Столбец `word` укажите в качестве индекса.\n",
        "\n",
        "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfMdd_PfUULj",
        "outputId": "41d39f86-cbab-4987-c9f3-d57471cf9c96"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "processed_words = {\n",
        "  'word': unique_words,\n",
        "  'stemmed_word': [stemmer.stem(word) for word in unique_words],\n",
        "  'normalized_word': [lemmatizer.lemmatize(word) for word in unique_words]\n",
        "}\n",
        "\n",
        "processed_words_df = pd.DataFrame(processed_words)\n",
        "processed_words_df.set_index('word', inplace=True)\n",
        "\n",
        "processed_words_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "Rrwf_Oa3SOOR",
        "outputId": "d2ea20b6-ffd9-4b32-817e-59bb16749ad2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             stemmed_word normalized_word\n",
              "word                                     \n",
              "fry-pan           fry-pan         fry-pan\n",
              "crehan             crehan          crehan\n",
              "coal-burning    coal-burn    coal-burning\n",
              "thidabeau       thidabeau       thidabeau\n",
              "parragon         parragon        parragon\n",
              "trolly             trolli          trolly\n",
              "before              befor          before\n",
              "135158             135158          135158\n",
              "bounty             bounti          bounty\n",
              "clonakilty     clonakilti      clonakilty"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-790b471b-09d9-4449-b147-7298c0603348\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stemmed_word</th>\n",
              "      <th>normalized_word</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fry-pan</th>\n",
              "      <td>fry-pan</td>\n",
              "      <td>fry-pan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>crehan</th>\n",
              "      <td>crehan</td>\n",
              "      <td>crehan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>coal-burning</th>\n",
              "      <td>coal-burn</td>\n",
              "      <td>coal-burning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thidabeau</th>\n",
              "      <td>thidabeau</td>\n",
              "      <td>thidabeau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parragon</th>\n",
              "      <td>parragon</td>\n",
              "      <td>parragon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>trolly</th>\n",
              "      <td>trolli</td>\n",
              "      <td>trolly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>before</th>\n",
              "      <td>befor</td>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135158</th>\n",
              "      <td>135158</td>\n",
              "      <td>135158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bounty</th>\n",
              "      <td>bounti</td>\n",
              "      <td>bounty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clonakilty</th>\n",
              "      <td>clonakilti</td>\n",
              "      <td>clonakilty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-790b471b-09d9-4449-b147-7298c0603348')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-790b471b-09d9-4449-b147-7298c0603348 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-790b471b-09d9-4449-b147-7298c0603348');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15192117-3661-4762-ac1c-1aca9033228b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15192117-3661-4762-ac1c-1aca9033228b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15192117-3661-4762-ac1c-1aca9033228b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_words_df",
              "summary": "{\n  \"name\": \"processed_words_df\",\n  \"rows\": 29744,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29744,\n        \"samples\": [\n          \"ham/kielbasa\",\n          \"tot\",\n          \"convection\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23276,\n        \"samples\": [\n          \"tempura\",\n          \"descent\",\n          \"thot\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27477,\n        \"samples\": [\n          \"cilantro\",\n          \"allt\",\n          \"incus\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMf5VoXsL3Z"
      },
      "source": [
        "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAUrin_5YpsN",
        "outputId": "cdb45c1b-cc76-445e-e22d-a45f8d90f7ea"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "filtered_words = [word for word in unique_words if word.lower() not in stopwords]\n",
        "\n",
        "total_words = len(unique_words)\n",
        "stopwords_count = total_words - len(filtered_words)\n",
        "stopwords_percent = stopwords_count / total_words\n",
        "\n",
        "original_top_10 = Counter(unique_words).most_common(10)\n",
        "filtered_top_10 = Counter(filtered_words).most_common(10)\n",
        "\n",
        "print(f\"Доля стоп-слов: {stopwords_percent:.2%}\")\n",
        "print(\"Топ-10 слов до удаления стоп-слов:\\n\", original_top_10)\n",
        "print(\"Топ-10 слов после удаления стоп-слов:\\n\", filtered_top_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q197NAhrYQOZ",
        "outputId": "3c135d57-0d46-4cf0-9b55-f2a2c7494201"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доля стоп-слов: 0.49%\n",
            "Топ-10 слов до удаления стоп-слов:\n",
            " [('fry-pan', 1), ('crehan', 1), ('coal-burning', 1), ('thidabeau', 1), ('parragon', 1), ('trolly', 1), ('before', 1), ('135158', 1), ('bounty', 1), ('clonakilty', 1)]\n",
            "Топ-10 слов после удаления стоп-слов:\n",
            " [('fry-pan', 1), ('crehan', 1), ('coal-burning', 1), ('thidabeau', 1), ('parragon', 1), ('trolly', 1), ('135158', 1), ('bounty', 1), ('clonakilty', 1), ('omnivores', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR3EXTNisL3Z"
      },
      "source": [
        "### Векторное представление текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhD4fiMAsL3Z"
      },
      "source": [
        "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "4RZAU4iuaIIC"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_recipes = data.sample(5)\n",
        "random_recipes_descriptions = random_recipes['description'].astype(str).tolist()\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "tfidf_matrix = vectorizer.fit_transform(random_recipes_descriptions)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_vectors = tfidf_matrix.toarray()\n",
        "\n",
        "for i, desc in enumerate(random_recipes_descriptions):\n",
        "  print(f\"Рецепт {i + 1}:\")\n",
        "  print(desc)\n",
        "  print(f\"\\nЧисловой вектор:\\n{tfidf_vectors[i]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mJ8sY_93aFlR",
        "outputId": "f63caa6c-8ba6-42ab-d3fa-56c68eeb91d3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Рецепт 1:\n",
            "tuna with a blast of wasabi. we nearly always have this with sliced crisp-tender green beans folded into the noodles. finely sliced snow peas work well too.\n",
            "\n",
            "Числовой вектор:\n",
            "[0.         0.         0.18188717 0.         0.         0.18188717\n",
            " 0.         0.18188717 0.         0.         0.         0.\n",
            " 0.         0.18188717 0.18188717 0.18188717 0.         0.\n",
            " 0.         0.         0.         0.         0.18188717 0.18188717\n",
            " 0.         0.         0.         0.         0.         0.18188717\n",
            " 0.         0.         0.         0.         0.18188717 0.\n",
            " 0.18188717 0.18188717 0.         0.         0.         0.\n",
            " 0.18188717 0.         0.         0.         0.         0.\n",
            " 0.36377434 0.18188717 0.         0.         0.         0.18188717\n",
            " 0.18188717 0.         0.08667021 0.18188717 0.         0.18188717\n",
            " 0.         0.18188717 0.18188717 0.18188717 0.         0.36377434\n",
            " 0.18188717 0.         0.         0.        ]\n",
            "\n",
            "Рецепт 2:\n",
            "this one is a bit healthier and there is no cream soup in it.  you can add or remove vegetables and it will still be good.\n",
            "\n",
            "Числовой вектор:\n",
            "[0.18971722 0.         0.         0.37943444 0.18971722 0.\n",
            " 0.18971722 0.         0.         0.18971722 0.         0.\n",
            " 0.18971722 0.         0.         0.         0.         0.\n",
            " 0.         0.18971722 0.         0.         0.         0.\n",
            " 0.         0.18971722 0.         0.         0.18971722 0.\n",
            " 0.37943444 0.30612532 0.         0.         0.         0.18971722\n",
            " 0.         0.         0.         0.18971722 0.15306266 0.\n",
            " 0.         0.         0.         0.         0.         0.18971722\n",
            " 0.         0.         0.         0.18971722 0.18971722 0.\n",
            " 0.         0.18971722 0.09040127 0.         0.         0.\n",
            " 0.18971722 0.         0.         0.         0.15306266 0.\n",
            " 0.         0.         0.15306266 0.        ]\n",
            "\n",
            "Рецепт 3:\n",
            "havn't tried this recipe yet but hopefully will soon!!\n",
            "\n",
            "Числовой вектор:\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.36444713 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.36444713 0.         0.         0.36444713 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.29403365 0.\n",
            " 0.         0.         0.36444713 0.         0.         0.\n",
            " 0.         0.         0.17366101 0.         0.36444713 0.\n",
            " 0.         0.         0.         0.         0.29403365 0.\n",
            " 0.         0.36444713 0.         0.        ]\n",
            "\n",
            "Рецепт 4:\n",
            "a great recipe from paula's home cooking, you'll like this! great for a potluck or a picnic!\n",
            "\n",
            "Числовой вектор:\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.25966825\n",
            " 0.         0.         0.         0.         0.20949871 0.\n",
            " 0.25966825 0.         0.51933651 0.         0.         0.\n",
            " 0.         0.         0.25966825 0.         0.         0.\n",
            " 0.         0.         0.25966825 0.25966825 0.         0.\n",
            " 0.         0.         0.         0.         0.20949871 0.25966825\n",
            " 0.         0.25966825 0.         0.25966825 0.20949871 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.12373331 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.20949871 0.        ]\n",
            "\n",
            "Рецепт 5:\n",
            "i found this on alleasyrecipes.com. i'm posting it for zwt 6.\r\n",
            "greece\n",
            "\n",
            "Числовой вектор:\n",
            "[0.         0.34241577 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.34241577 0.\n",
            " 0.         0.         0.         0.         0.27625889 0.34241577\n",
            " 0.         0.         0.         0.34241577 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.27625889 0.         0.         0.         0.\n",
            " 0.         0.         0.34241577 0.         0.         0.\n",
            " 0.         0.         0.34241577 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.16316295 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.34241577]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkqps3sdsL3Z"
      },
      "source": [
        "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "metadata": {
        "id": "ONj-mmbdaF8d"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_recipes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "LeGzmx0tj6h2",
        "outputId": "5e09cc22-8d66-4bde-a6c0-ee32cdfddf7e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  name      id  minutes  \\\n",
              "29057  wasabi tuna steaks with hokkien or udon noodles  178540       70   \n",
              "5508                    chicken   brown rice casserole  192281       85   \n",
              "29947                   zucchini meat sauce with pasta  253264       30   \n",
              "26597                        sweet and sour bean salad  187954       25   \n",
              "10775                            fassoulada  bean soup  424172      160   \n",
              "\n",
              "       contributor_id  submitted  n_steps  \\\n",
              "29057          279205 2006-07-20      9.0   \n",
              "5508           366730 2006-10-25      NaN   \n",
              "29947          275742 2007-09-17      NaN   \n",
              "26597           37449 2006-09-27     13.0   \n",
              "10775          178427 2010-05-10      NaN   \n",
              "\n",
              "                                             description  n_ingredients  \\\n",
              "29057  tuna with a blast of wasabi. we nearly always ...            6.0   \n",
              "5508   this one is a bit healthier and there is no cr...            9.0   \n",
              "29947  havn't tried this recipe yet but hopefully wil...            6.0   \n",
              "26597  a great recipe from paula's home cooking, you'...           14.0   \n",
              "10775  i found this on alleasyrecipes.com. i'm postin...            NaN   \n",
              "\n",
              "                                preprocessed_description  \n",
              "29057  tuna with a blast of wasabi we nearly always h...  \n",
              "5508   this one is a bit healthier and there is no cr...  \n",
              "29947  havnt tried this recipe yet but hopefully will...  \n",
              "26597  a great recipe from paulas home cooking youll ...  \n",
              "10775  i found this on alleasyrecipescom im posting i...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7671e218-8e27-45c9-b4d3-ae995678f7b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>description</th>\n",
              "      <th>n_ingredients</th>\n",
              "      <th>preprocessed_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29057</th>\n",
              "      <td>wasabi tuna steaks with hokkien or udon noodles</td>\n",
              "      <td>178540</td>\n",
              "      <td>70</td>\n",
              "      <td>279205</td>\n",
              "      <td>2006-07-20</td>\n",
              "      <td>9.0</td>\n",
              "      <td>tuna with a blast of wasabi. we nearly always ...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>tuna with a blast of wasabi we nearly always h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5508</th>\n",
              "      <td>chicken   brown rice casserole</td>\n",
              "      <td>192281</td>\n",
              "      <td>85</td>\n",
              "      <td>366730</td>\n",
              "      <td>2006-10-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>this one is a bit healthier and there is no cr...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>this one is a bit healthier and there is no cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29947</th>\n",
              "      <td>zucchini meat sauce with pasta</td>\n",
              "      <td>253264</td>\n",
              "      <td>30</td>\n",
              "      <td>275742</td>\n",
              "      <td>2007-09-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>havn't tried this recipe yet but hopefully wil...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>havnt tried this recipe yet but hopefully will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26597</th>\n",
              "      <td>sweet and sour bean salad</td>\n",
              "      <td>187954</td>\n",
              "      <td>25</td>\n",
              "      <td>37449</td>\n",
              "      <td>2006-09-27</td>\n",
              "      <td>13.0</td>\n",
              "      <td>a great recipe from paula's home cooking, you'...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>a great recipe from paulas home cooking youll ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10775</th>\n",
              "      <td>fassoulada  bean soup</td>\n",
              "      <td>424172</td>\n",
              "      <td>160</td>\n",
              "      <td>178427</td>\n",
              "      <td>2010-05-10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i found this on alleasyrecipes.com. i'm postin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i found this on alleasyrecipescom im posting i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7671e218-8e27-45c9-b4d3-ae995678f7b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7671e218-8e27-45c9-b4d3-ae995678f7b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7671e218-8e27-45c9-b4d3-ae995678f7b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b2aa193-e660-4993-b5a5-08cd66f550d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b2aa193-e660-4993-b5a5-08cd66f550d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b2aa193-e660-4993-b5a5-08cd66f550d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "random_recipes",
              "summary": "{\n  \"name\": \"random_recipes\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"chicken   brown rice casserole\",\n          \"fassoulada  bean soup\",\n          \"zucchini meat sauce with pasta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 103194,\n        \"min\": 178540,\n        \"max\": 424172,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          192281,\n          424172,\n          253264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"minutes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 25,\n        \"max\": 160,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          85,\n          160,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contributor_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 125412,\n        \"min\": 37449,\n        \"max\": 366730,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          366730,\n          178427,\n          275742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"submitted\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2006-07-20 00:00:00\",\n        \"max\": \"2010-05-10 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2006-10-25 00:00:00\",\n          \"2010-05-10 00:00:00\",\n          \"2007-09-17 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_steps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8284271247461903,\n        \"min\": 9.0,\n        \"max\": 13.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          13.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"this one is a bit healthier and there is no cream soup in it.  you can add or remove vegetables and it will still be good.\",\n          \"i found this on alleasyrecipes.com. i'm posting it for zwt 6.\\r\\ngreece\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_ingredients\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.774917217635375,\n        \"min\": 6.0,\n        \"max\": 14.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"this one is a bit healthier and there is no cream soup in it  you can add or remove vegetables and it will still be good\",\n          \"i found this on alleasyrecipescom im posting it for zwt 6greece\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_names = random_recipes['name'].tolist()\n",
        "\n",
        "tfidf_matrix_array = tfidf_matrix.toarray()\n",
        "\n",
        "distances = pd.DataFrame(index=recipe_names, columns=recipe_names)\n",
        "\n",
        "for i in range(len(recipe_names)):\n",
        "  for j in range(len(recipe_names)):\n",
        "    if i != j:\n",
        "      distances.iloc[i, j] = cosine(tfidf_matrix_array[i], tfidf_matrix_array[j])\n",
        "    else:\n",
        "      distances.iloc[i, j] = 0.0  # Расстояние между рецептом и самим собой\n",
        "\n",
        "distances = distances.astype(float)\n",
        "\n",
        "distances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "JJbcxF3wjVnF",
        "outputId": "2c07cd09-9beb-4725-93db-4cfa3b35b31a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 wasabi tuna steaks with hokkien or udon noodles  \\\n",
              "wasabi tuna steaks with hokkien or udon noodles                                         0.000000   \n",
              "chicken   brown rice casserole                                                          0.992165   \n",
              "zucchini meat sauce with pasta                                                          0.984949   \n",
              "sweet and sour bean salad                                                               0.989276   \n",
              "fassoulada  bean soup                                                                   0.985859   \n",
              "\n",
              "                                                 chicken   brown rice casserole  \\\n",
              "wasabi tuna steaks with hokkien or udon noodles                        0.992165   \n",
              "chicken   brown rice casserole                                         0.000000   \n",
              "zucchini meat sauce with pasta                                         0.939295   \n",
              "sweet and sour bean salad                                              0.924681   \n",
              "fassoulada  bean soup                                                  0.900680   \n",
              "\n",
              "                                                 zucchini meat sauce with pasta  \\\n",
              "wasabi tuna steaks with hokkien or udon noodles                        0.984949   \n",
              "chicken   brown rice casserole                                         0.939295   \n",
              "zucchini meat sauce with pasta                                         0.000000   \n",
              "sweet and sour bean salad                                              0.916913   \n",
              "fassoulada  bean soup                                                  0.971665   \n",
              "\n",
              "                                                 sweet and sour bean salad  \\\n",
              "wasabi tuna steaks with hokkien or udon noodles                   0.989276   \n",
              "chicken   brown rice casserole                                    0.924681   \n",
              "zucchini meat sauce with pasta                                    0.916913   \n",
              "sweet and sour bean salad                                         0.000000   \n",
              "fassoulada  bean soup                                             0.921935   \n",
              "\n",
              "                                                 fassoulada  bean soup  \n",
              "wasabi tuna steaks with hokkien or udon noodles               0.985859  \n",
              "chicken   brown rice casserole                                0.900680  \n",
              "zucchini meat sauce with pasta                                0.971665  \n",
              "sweet and sour bean salad                                     0.921935  \n",
              "fassoulada  bean soup                                         0.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f1aa62d-c82d-4078-b414-53959e3282c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wasabi tuna steaks with hokkien or udon noodles</th>\n",
              "      <th>chicken   brown rice casserole</th>\n",
              "      <th>zucchini meat sauce with pasta</th>\n",
              "      <th>sweet and sour bean salad</th>\n",
              "      <th>fassoulada  bean soup</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>wasabi tuna steaks with hokkien or udon noodles</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.992165</td>\n",
              "      <td>0.984949</td>\n",
              "      <td>0.989276</td>\n",
              "      <td>0.985859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chicken   brown rice casserole</th>\n",
              "      <td>0.992165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.939295</td>\n",
              "      <td>0.924681</td>\n",
              "      <td>0.900680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zucchini meat sauce with pasta</th>\n",
              "      <td>0.984949</td>\n",
              "      <td>0.939295</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.916913</td>\n",
              "      <td>0.971665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sweet and sour bean salad</th>\n",
              "      <td>0.989276</td>\n",
              "      <td>0.924681</td>\n",
              "      <td>0.916913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fassoulada  bean soup</th>\n",
              "      <td>0.985859</td>\n",
              "      <td>0.900680</td>\n",
              "      <td>0.971665</td>\n",
              "      <td>0.921935</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f1aa62d-c82d-4078-b414-53959e3282c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f1aa62d-c82d-4078-b414-53959e3282c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f1aa62d-c82d-4078-b414-53959e3282c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b9ea7e-a700-4565-853d-760cde971eb7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b9ea7e-a700-4565-853d-760cde971eb7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b9ea7e-a700-4565-853d-760cde971eb7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "distances",
              "summary": "{\n  \"name\": \"distances\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"wasabi tuna steaks with hokkien or udon noodles\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44188408788786576,\n        \"min\": 0.0,\n        \"max\": 0.9921649026020484,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9921649026020484,\n          0.9858586328648893,\n          0.9849487635049555\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chicken   brown rice casserole\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42136246773033353,\n        \"min\": 0.0,\n        \"max\": 0.9921649026020484,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0,\n          0.9006800216625221,\n          0.9392952504140122\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zucchini meat sauce with pasta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42712395629444266,\n        \"min\": 0.0,\n        \"max\": 0.9849487635049555,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9392952504140122,\n          0.9716649573623941,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sweet and sour bean salad\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42062057991091556,\n        \"min\": 0.0,\n        \"max\": 0.9892760075535951,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9246814903190147,\n          0.9219354268171223,\n          0.9169126760069086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fassoulada  bean soup\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4240722920716276,\n        \"min\": 0.0,\n        \"max\": 0.9858586328648893,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9006800216625221,\n          0.0,\n          0.9716649573623941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4yyBnr5sL3Z"
      },
      "source": [
        "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все рецепты в большей мере отличаются друг от друга, но есть два, которые немного, но похожи, если судить по их косинусному расстоянию - это chicken brown rice casserole и fassoulada  bean soup. У них косинусное расстояние 0.900680, что является самым малым, не считая рецептов, которые сравниваются сами с собой."
      ],
      "metadata": {
        "id": "p2YwxnOclSgo"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}